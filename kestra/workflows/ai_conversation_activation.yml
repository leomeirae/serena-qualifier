id: ai-conversation-activation
namespace: serena.energia
description: "Workflow ativado quando lead responde qualquer mensagem - inicia conversa IA REAL"

labels:
  version: "2.0.0"
  environment: "production"
  system: "serena-qualifier"

triggers:
  - id: whatsapp-response-webhook
    type: io.kestra.plugin.core.trigger.Webhook
    key: "webhook"

tasks:
  # TASK 1: Classificar Inten√ß√£o com IA Real
  - id: classify-user-intention
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      image: "serena/kestra-python-runner:latest"
      pullPolicy: "NEVER"
      networkMode: "serena-qualifier_kestra-network"
    env:
      LEAD_PHONE: "{{ trigger.body.lead_phone }}"
      LEAD_MESSAGE: "{{ trigger.body.lead_message }}"
      MESSAGE_TYPE: "{{ trigger.body.message_type }}"
      MESSAGE_ID: "{{ trigger.body.message_id }}"
    script: |
      import sys
      sys.path.append('.')
      # Carregar .env primeiro
      from dotenv import load_dotenv
      load_dotenv('/app/.env')
      
      from scripts.ai_agent import process_ai_request
      import os
      import json
      
      phone = os.getenv("LEAD_PHONE")
      message = os.getenv("LEAD_MESSAGE")
      msg_type = os.getenv("MESSAGE_TYPE")
      msg_id = os.getenv("MESSAGE_ID")
      
      print(f"üéØ CLASSIFICANDO INTEN√á√ÉO - Lead {phone}")
      print(f"üí¨ Mensagem: '{message}'")
      
      # Classificar inten√ß√£o com IA REAL (OpenAI GPT-4o-mini)
      try:
          intention_result = process_ai_request(
              phone_number=phone,
              message=message,
              action="classify"
          )
          
          print(f"ü§ñ Inten√ß√£o classificada: {intention_result.get('intention', 'erro')}")
          print(f"üéØ Confian√ßa: {intention_result.get('confidence', 'baixa')}")
          
          # Adicionar contexto do trigger
          context = {
              "phone": phone,
              "message": message,
              "message_type": msg_type,
              "message_id": msg_id,
              "intention_result": intention_result,
              "timestamp": os.getenv("KESTRA_TIMESTAMP", "")
          }
          
          print('::' + json.dumps({"outputs": {"context": context}}) + '::')
          
      except Exception as e:
          print(f"‚ùå Erro na classifica√ß√£o: {str(e)}")
          error_context = {
              "phone": phone,
              "message": message,
              "error": str(e),
              "intention_result": {"intention": "incompreensivel", "error": str(e)}
          }
          print('::' + json.dumps({"outputs": {"context": error_context}}) + '::')

  # TASK 2: Extrair Dados (se necess√°rio)
  - id: extract-user-data
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      image: "serena/kestra-python-runner:latest"
      pullPolicy: "NEVER"
      networkMode: "serena-qualifier_kestra-network"
    env:
      CONTEXT_JSON: "{{ outputs['classify-user-intention'].vars.context | json }}"
    script: |
      import sys
      sys.path.append('.')
      # Carregar .env primeiro
      from dotenv import load_dotenv
      load_dotenv('/app/.env')
      
      from scripts.ai_agent import process_ai_request
      from utils.conversation_manager import manage_conversation
      import os
      import json
      
      context = json.loads(os.getenv("CONTEXT_JSON", "{}"))
      phone = context.get("phone")
      message = context.get("message")
      intention = context.get("intention_result", {}).get("intention", "")
      
      print(f"üîç EXTRAINDO DADOS - Lead {phone}")
      print(f"üéØ Inten√ß√£o: {intention}")
      
      # Determinar que tipo de dado extrair baseado na inten√ß√£o
      extraction_map = {
          "informou_cidade": "cidade",
          "informou_valor_conta": "valor_conta", 
          "informou_tipo_imovel": "tipo_imovel"
      }
      
      extracted_data = {}
      
      if intention in extraction_map:
          data_type = extraction_map[intention]
          
          try:
              extract_result = process_ai_request(
                  phone_number=phone,
                  message=message,
                  action="extract",
                  data_type=data_type
              )
              
              extracted_data = extract_result
              print(f"üìä Dados extra√≠dos ({data_type}): {extract_result.get('extracted_value', 'N/A')}")
              
              # Salvar dados extra√≠dos no hist√≥rico com metadata
              if extract_result.get('success') and extract_result.get('extracted_value') != 'n√£o_identificado':
                  metadata = {
                      "intention": intention,
                      "extracted_data": extract_result
                  }
                  
                  manage_conversation(
                      action="add_message",
                      phone_number=phone,
                      role="user",
                      content=message,
                      metadata=metadata
                  )
              
          except Exception as e:
              print(f"‚ùå Erro na extra√ß√£o: {str(e)}")
              extracted_data = {"error": str(e)}
      else:
          print(f"‚ÑπÔ∏è Inten√ß√£o '{intention}' n√£o requer extra√ß√£o de dados")
      
      # Atualizar contexto
      context["extracted_data"] = extracted_data
      
      print('::' + json.dumps({"outputs": {"context": context}}) + '::')

  # TASK 3: Gerar Resposta IA Contextualizada
  - id: generate-ai-response
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      image: "serena/kestra-python-runner:latest"
      pullPolicy: "NEVER"
      networkMode: "serena-qualifier_kestra-network"
    env:
      CONTEXT_JSON: "{{ outputs['extract-user-data'].vars.context | json }}"
    script: |
      import sys
      sys.path.append('.')
      # Carregar .env primeiro
      from dotenv import load_dotenv
      load_dotenv('/app/.env')
      
      from scripts.ai_agent import process_ai_request
      from utils.conversation_manager import manage_conversation
      import os
      import json
      
      context = json.loads(os.getenv("CONTEXT_JSON", "{}"))
      phone = context.get("phone")
      message = context.get("message")
      intention = context.get("intention_result", {}).get("intention", "")
      extracted_data = context.get("extracted_data", {})
      
      print(f"ü§ñ GERANDO RESPOSTA IA - Lead {phone}")
      print(f"üéØ Inten√ß√£o: {intention}")
      
      # Obter dados de qualifica√ß√£o atuais
      try:
          qualification_data = manage_conversation(
              action="get_qualification",
              phone_number=phone
          )
          
          # Preparar contexto para IA
          ai_context = {
              "intention": intention,
              "extracted_data": extracted_data,
              "qualification_data": qualification_data,
              "conversation_stage": "active"
          }
          
          # Gerar resposta com IA REAL (OpenAI GPT-4o-mini)
          response_result = process_ai_request(
              phone_number=phone,
              message=message,
              action="respond",
              context=ai_context
          )
          
          ai_response = response_result.get("response", "Desculpe, houve um problema. Pode repetir?")
          success = response_result.get("success", False)
          
          print(f"üí¨ Resposta IA gerada: '{ai_response[:100]}...'")
          print(f"‚úÖ Sucesso: {success}")
          
          # Atualizar contexto final
          final_context = {
              **context,
              "ai_response": ai_response,
              "response_success": success,
              "tokens_used": response_result.get("tokens_used", 0),
              "qualification_data": qualification_data
          }
          
          print('::' + json.dumps({"outputs": {"final_context": final_context}}) + '::')
          
      except Exception as e:
          print(f"‚ùå Erro ao gerar resposta: {str(e)}")
          error_response = "Desculpe, tive um problema t√©cnico. Pode repetir sua mensagem?"
          
          error_context = {
              **context,
              "ai_response": error_response,
              "response_success": False,
              "error": str(e)
          }
          print('::' + json.dumps({"outputs": {"final_context": error_context}}) + '::')

  # TASK 4: Enviar Resposta via WhatsApp
  - id: send-ai-response
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      image: "serena/kestra-python-runner:latest"
      pullPolicy: "NEVER"
      networkMode: "serena-qualifier_kestra-network"
    env:
      FINAL_CONTEXT_JSON: "{{ outputs['generate-ai-response'].vars.final_context | json }}"
    script: |
      import os
      import json
      import requests
      
      context = json.loads(os.getenv("FINAL_CONTEXT_JSON", "{}"))
      phone = context.get("phone")
      ai_response = context.get("ai_response")
      response_success = context.get("response_success", False)
      
      print(f"üì± ENVIANDO RESPOSTA - Lead {phone}")
      print(f"üí¨ Resposta: '{ai_response[:100]}...'")
      
      if not response_success:
          print("‚ö†Ô∏è Resposta IA com erro, enviando mesmo assim")
      
      # Enviar via WhatsApp REAL
      try:
          whatsapp_url = "http://whatsapp-service:8000/whatsapp/send_text_message"
          payload = {
              "phone": phone,
              "message": ai_response
          }
          
          print("üì§ Enviando via WhatsApp Service...")
          
          response = requests.post(whatsapp_url, json=payload, timeout=30)
          response.raise_for_status()
          
          result = response.json()
          message_id = result.get("message_id", "")
          
          print(f"‚úÖ Mensagem enviada com sucesso!")
          print(f"üì¨ Message ID: {message_id}")
          
          # Resultado final
          final_result = {
              "conversation_completed": True,
              "message_sent": True,
              "message_id": message_id,
              "ai_tokens_used": context.get("tokens_used", 0),
              "qualification_status": context.get("qualification_data", {}).get("status", "em_progresso")
          }
          
      except Exception as e:
          print(f"‚ùå Erro ao enviar mensagem: {str(e)}")
          final_result = {
              "conversation_completed": False,
              "message_sent": False,
              "error": str(e)
          }
      
      print('::' + json.dumps({"outputs": {"final_result": final_result}}) + '::') 