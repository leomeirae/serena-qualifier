id: ai-conversation-activation-v3-langchain
namespace: serena.energia
description: "Workflow OTIMIZADO com SerenaAIAgent LangChain + Imagem Docker Customizada"

labels:
  version: "5.0.0"
  environment: "production"
  system: "serena-qualifier"
  framework: "langchain"
  agent: "serena-ai-agent"
  docker_strategy: "custom_image"

triggers:
  - id: whatsapp-response-webhook-v3
    type: io.kestra.plugin.core.trigger.Webhook
    key: "webhook_v3"

inputs:
  - id: lead_phone
    type: STRING
    required: false
  - id: lead_message
    type: STRING
    required: false
  - id: message_type
    type: STRING
    required: false
    defaults: "text"
  - id: message_id
    type: STRING
    required: false
  - id: media_id
    type: STRING
    required: false

tasks:
  # TASK 1: An√°lise Inteligente Unificada
  - id: intelligent-analysis
    type: io.kestra.plugin.scripts.python.Script
    description: "An√°lise inteligente usando SerenaAIAgent com LangChain - Imagem Customizada"
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      image: "serena-runner:latest"
      pullPolicy: "NEVER"
      networkMode: "serena-qualifier_kestra-network"
      fileHandlingStrategy: VOLUME
      # Volumes removidos - todos os arquivos j√° est√£o na imagem!
    env:
      DEBUG: "true"
      MIN_QUALIFY_AMOUNT: "100"
      LEAD_PHONE: "{{ inputs.lead_phone | default(trigger.body.lead_phone | default('')) }}"
      LEAD_MESSAGE: "{{ inputs.lead_message | default(trigger.body.lead_message | default('')) }}"
      MESSAGE_TYPE: "{{ inputs.message_type | default(trigger.body.message_type | default('text')) }}"
      MESSAGE_ID: "{{ inputs.message_id | default(trigger.body.message_id | default('')) }}"
      MEDIA_ID: "{{ inputs.media_id | default(trigger.body.media_id | default('')) }}"
    script: |
      # Carregar vari√°veis de ambiente
      from dotenv import load_dotenv
      load_dotenv('/app/.env')
      
      # Importar SerenaAIAgent otimizado
      from scripts.serena_agent.core_agent import SerenaAIAgent
      import json
      import time
      import os
      
      phone = os.getenv("LEAD_PHONE")
      message = os.getenv("LEAD_MESSAGE")
      msg_type = os.getenv("MESSAGE_TYPE")
      msg_id = os.getenv("MESSAGE_ID")
      media_id = os.getenv("MEDIA_ID")
      
      print(f"üöÄ AN√ÅLISE INTELIGENTE V5 - Lead {phone}")
      print(f"üí¨ Mensagem: '{message}'")
      print(f"ü§ñ Framework: SerenaAIAgent + LangChain (Imagem Customizada)")
      
      start_time = time.time()
      agent = SerenaAIAgent()
      
      try:
          # 1. Classifica√ß√£o + 2. Extra√ß√£o em paralelo
          classify_result = agent.process_conversation(phone, message, "classify")
          extract_result = agent.process_conversation(phone, message, "extract")
          
          intention = classify_result.get("response", "unclear")
          
          try:
              extracted_data = json.loads(extract_result.get("response", "{}"))
          except json.JSONDecodeError:
              extracted_data = {"phone": phone}
          
          # 3. Detectar fatura
          is_invoice = (
              msg_type in ["image", "document"] or 
              intention in ["send_invoice", "enviou_fatura"] or
              "fatura" in message.lower()
          )
          
          analysis_context = {
              "phone": phone,
              "message": message,
              "message_type": msg_type,
              "media_id": media_id,
              "intention": intention,
              "extracted_data": extracted_data,
              "is_invoice": is_invoice,
              "needs_ocr": is_invoice and bool(media_id),
              "has_langchain": agent.agent_executor is not None,
              "processing_time": time.time() - start_time,
              "analysis_success": True,
              "docker_strategy": "custom_image"
          }
          
          print(f"‚úÖ Inten√ß√£o: {intention}")
          print(f"üìÑ √â fatura: {is_invoice}")
          print(f"üîß Estrat√©gia Docker: Imagem Customizada")
          
      except Exception as e:
          print(f"‚ùå Erro: {str(e)}")
          analysis_context = {
              "phone": phone,
              "message": message,
              "analysis_success": False,
              "error": str(e),
              "error_type": type(e).__name__,
              "is_invoice": False,
              "docker_strategy": "custom_image"
          }
      
      print('::' + json.dumps({"outputs": {"analysis_context": analysis_context}}) + '::')

  # TASK 2: OCR Inteligente (condicional)
  - id: smart-ocr-processing
    type: io.kestra.plugin.scripts.python.Script
    runIf: "{{ outputs['intelligent-analysis'].vars.analysis_context.needs_ocr == true }}"
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      image: "serena-runner:latest"
      pullPolicy: "NEVER"
      networkMode: "serena-qualifier_kestra-network"
      fileHandlingStrategy: VOLUME
    env:
      ANALYSIS_CONTEXT: "{{ outputs['intelligent-analysis'].vars.analysis_context | json }}"
    script: |
      from dotenv import load_dotenv
      load_dotenv('/app/.env')
      
      from scripts.serena_agent.tools.ocr_tool import ocr_tool_function
      import os
      import json
      import time
      
      context = json.loads(os.getenv("ANALYSIS_CONTEXT", "{}"))
      phone = context.get("phone")
      media_id = context.get("media_id")
      
      print(f"üìÑ OCR INTELIGENTE V5 - Lead {phone}")
      print(f"üîß Estrat√©gia: Imagem Customizada")
      
      try:
          start_time = time.time()
          
          # Processar fatura
          amount_result = ocr_tool_function({
              "action": "extract_amount",
              "image_data": media_id
          })
          
          ocr_data = {
              "amount": amount_result.get("result", {}).get("amount", 0),
              "success": amount_result.get("success", False),
              "processing_time": time.time() - start_time
          }
          
          valor_conta = ocr_data["amount"]
          min_amount = float(os.getenv("MIN_QUALIFY_AMOUNT", "100"))
          is_qualified = valor_conta >= min_amount
          
          ocr_data.update({
              "valor_conta": valor_conta,
              "is_qualified": is_qualified
          })
          
          print(f"üí∞ Valor: R$ {valor_conta:.2f}")
          print(f"‚úÖ Qualificado: {is_qualified}")
          
          context["ocr_result"] = ocr_data
          context["is_invoice_processed"] = True
          
      except Exception as e:
          print(f"‚ùå Erro OCR: {str(e)}")
          context["ocr_result"] = {"error": str(e), "success": False}
      
      print('::' + json.dumps({"outputs": {"ocr_context": context}}) + '::')

  # TASK 3: Resposta LangChain
  - id: langchain-response
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      image: "serena-runner:latest"
      pullPolicy: "NEVER"
      networkMode: "serena-qualifier_kestra-network"
      fileHandlingStrategy: VOLUME
    env:
      ANALYSIS_CONTEXT: "{{ outputs['intelligent-analysis'].vars.analysis_context | json }}"
      OCR_CONTEXT: "{{ outputs['smart-ocr-processing'].vars.ocr_context | json | default('{}') }}"
    script: |
      from dotenv import load_dotenv
      load_dotenv('/app/.env')
      
      from scripts.serena_agent.core_agent import SerenaAIAgent
      import os
      import json
      import time
      
      analysis_ctx = json.loads(os.getenv("ANALYSIS_CONTEXT", "{}"))
      ocr_ctx = json.loads(os.getenv("OCR_CONTEXT", "{}"))
      
      context = ocr_ctx if ocr_ctx else analysis_ctx
      
      phone = context.get("phone")
      message = context.get("message")
      intention = context.get("intention")
      
      print(f"ü§ñ RESPOSTA LANGCHAIN V5 - Lead {phone}")
      print(f"üéØ Inten√ß√£o: {intention}")
      print(f"üîß Estrat√©gia: Imagem Customizada")
      
      try:
          start_time = time.time()
          agent = SerenaAIAgent()
          
          # Preparar contexto
          if context.get("is_invoice_processed"):
              ocr_result = context.get("ocr_result", {})
              enhanced_message = f"Lead enviou fatura. Valor: R$ {ocr_result.get('valor_conta', 0):.2f}. Qualificado: {ocr_result.get('is_qualified', False)}. Mensagem: {message}"
          else:
              enhanced_message = f"Conversa com lead. Inten√ß√£o: {intention}. Mensagem: {message}"
          
          # RESPOSTA VIA LANGCHAIN
          response_result = agent.process_conversation(phone, enhanced_message, "respond")
          
          ai_response = response_result.get("response", "Problema t√©cnico")
          method_used = response_result.get("method", "unknown")
          
          final_context = {
              **context,
              "ai_response": ai_response,
              "method_used": method_used,
              "response_time": time.time() - start_time,
              "response_success": True
          }
          
          print(f"üí¨ Resposta: '{ai_response[:80]}...'")
          print(f"‚öôÔ∏è  M√©todo: {method_used}")
          
      except Exception as e:
          print(f"‚ùå Erro: {str(e)}")
          final_context = {
              **context,
              "ai_response": "Desculpe, problema t√©cnico.",
              "error": str(e)
          }
      
      print('::' + json.dumps({"outputs": {"final_context": final_context}}) + '::')

  # TASK 4: Envio + Analytics
  - id: send-and-analytics
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      image: "serena-runner:latest"
      pullPolicy: "NEVER"
      networkMode: "serena-qualifier_kestra-network"
      fileHandlingStrategy: VOLUME
    env:
      DEBUG: "false"
      WHATSAPP_API_URL: "http://whatsapp-service:8000/whatsapp/send_text_message"
      FINAL_CONTEXT: "{{ outputs['langchain-response'].vars.final_context | json }}"
    script: |
      from dotenv import load_dotenv
      load_dotenv('/app/.env')
      
      import json
      import requests
      import time
      
      context = json.loads(os.getenv("FINAL_CONTEXT", "{}"))
      phone = context.get("phone")
      ai_response = context.get("ai_response")
      method_used = context.get("method_used", "unknown")
      
      print(f"üì± ENVIO + ANALYTICS V5 - Lead {phone}")
      print(f"‚öôÔ∏è  M√©todo: {method_used}")
      print(f"üîß Estrat√©gia: Imagem Docker Customizada")
      
      try:
          # Enviar mensagem
          whatsapp_url = os.getenv("WHATSAPP_API_URL", "http://whatsapp-service:8000/whatsapp/send_text_message")
          payload = {"phone": phone, "message": ai_response}
          
          response = requests.post(whatsapp_url, json=payload, timeout=30)
          response.raise_for_status()
          
          result = response.json()
          message_id = result.get("message_id", "")
          
          print(f"‚úÖ Enviado! ID: {message_id}")
          
          # Analytics
          analytics = {
              "workflow_version": "v5_custom_image",
              "framework": method_used,
              "langchain_used": method_used == "langchain",
              "invoice_processed": context.get("is_invoice_processed", False),
              "qualified": context.get("ocr_result", {}).get("is_qualified", False),
              "message_sent": True,
              "timestamp": time.time(),
              "docker_strategy": "custom_image",
              "volume_issues_resolved": True
          }
          
          final_result = {
              "success": True,
              "message_id": message_id,
              "analytics": analytics
          }
          
      except Exception as e:
          print(f"‚ùå Erro: {str(e)}")
          final_result = {"success": False, "error": str(e)}
      
      print('::' + json.dumps({"outputs": {"result": final_result}}) + '::') 